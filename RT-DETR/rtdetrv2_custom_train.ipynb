{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28013,
     "status": "ok",
     "timestamp": 1734009731830,
     "user": {
      "displayName": "Tai Do",
      "userId": "13979933527558473981"
     },
     "user_tz": -480
    },
    "id": "rh5HIAG5URJT",
    "outputId": "c760ab20-bb2d-4019-cf05-6128d29bad76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# set up for google colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# %cd /content/drive/MyDrive/rt-detrv2-fine-tune/RT-DETR/rtdetrv2_pytorch\n",
    "\n",
    "# !pip install supervision\n",
    "# !pip install torchmetrics\n",
    "# !pip install albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgZiX1X5qU0c"
   },
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82185,
     "status": "ok",
     "timestamp": 1734009841174,
     "user": {
      "displayName": "Tai Do",
      "userId": "13979933527558473981"
     },
     "user_tz": -480
    },
    "id": "YK8GJCINqYG8",
    "outputId": "8b48b7e1-b109-462a-da6e-d42cdbb70f95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lyuwenyu/storage/releases/download/v0.1/ResNet18_vd_pretrained_from_paddle.pth\" to /root/.cache/torch/hub/checkpoints/ResNet18_vd_pretrained_from_paddle.pth\n",
      "100%|██████████| 42.8M/42.8M [00:00<00:00, 225MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load PResNet18 state_dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-ca9084159120>:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint=torch.load(args.resume_path,map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched and loaded weight for: backbone.conv1.conv1_1.conv.weight\n",
      "Matched and loaded weight for: backbone.conv1.conv1_1.norm.weight\n",
      "Matched and loaded weight for: backbone.conv1.conv1_1.norm.bias\n",
      "Matched and loaded weight for: backbone.conv1.conv1_1.norm.running_mean\n",
      "Matched and loaded weight for: backbone.conv1.conv1_1.norm.running_var\n",
      "Matched and loaded weight for: backbone.conv1.conv1_1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.conv1.conv1_2.conv.weight\n",
      "Matched and loaded weight for: backbone.conv1.conv1_2.norm.weight\n",
      "Matched and loaded weight for: backbone.conv1.conv1_2.norm.bias\n",
      "Matched and loaded weight for: backbone.conv1.conv1_2.norm.running_mean\n",
      "Matched and loaded weight for: backbone.conv1.conv1_2.norm.running_var\n",
      "Matched and loaded weight for: backbone.conv1.conv1_2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.conv1.conv1_3.conv.weight\n",
      "Matched and loaded weight for: backbone.conv1.conv1_3.norm.weight\n",
      "Matched and loaded weight for: backbone.conv1.conv1_3.norm.bias\n",
      "Matched and loaded weight for: backbone.conv1.conv1_3.norm.running_mean\n",
      "Matched and loaded weight for: backbone.conv1.conv1_3.norm.running_var\n",
      "Matched and loaded weight for: backbone.conv1.conv1_3.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.short.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.short.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.short.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.short.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.short.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.short.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2a.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2a.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2a.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2a.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2a.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2a.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2b.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2b.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2b.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2b.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2b.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.0.branch2b.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2a.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2a.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2a.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2a.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2a.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2a.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2b.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2b.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2b.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2b.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2b.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.0.blocks.1.branch2b.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.short.conv.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.short.conv.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.short.conv.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.short.conv.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.short.conv.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.short.conv.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2a.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2a.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2a.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2a.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2a.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2a.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2b.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2b.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2b.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2b.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2b.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.0.branch2b.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2a.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2a.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2a.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2a.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2a.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2a.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2b.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2b.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2b.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2b.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2b.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.1.blocks.1.branch2b.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.short.conv.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.short.conv.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.short.conv.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.short.conv.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.short.conv.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.short.conv.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2a.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2a.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2a.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2a.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2a.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2a.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2b.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2b.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2b.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2b.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2b.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.0.branch2b.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2a.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2a.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2a.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2a.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2a.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2a.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2b.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2b.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2b.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2b.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2b.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.2.blocks.1.branch2b.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.short.conv.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.short.conv.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.short.conv.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.short.conv.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.short.conv.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.short.conv.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2a.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2a.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2a.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2a.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2a.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2a.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2b.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2b.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2b.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2b.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2b.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.0.branch2b.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2a.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2a.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2a.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2a.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2a.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2a.norm.num_batches_tracked\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2b.conv.weight\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2b.norm.weight\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2b.norm.bias\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2b.norm.running_mean\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2b.norm.running_var\n",
      "Matched and loaded weight for: backbone.res_layers.3.blocks.1.branch2b.norm.num_batches_tracked\n",
      "Matched and loaded weight for: decoder.anchors\n",
      "Matched and loaded weight for: decoder.valid_mask\n",
      "Matched and loaded weight for: decoder.input_proj.0.conv.weight\n",
      "Matched and loaded weight for: decoder.input_proj.0.norm.weight\n",
      "Matched and loaded weight for: decoder.input_proj.0.norm.bias\n",
      "Matched and loaded weight for: decoder.input_proj.0.norm.running_mean\n",
      "Matched and loaded weight for: decoder.input_proj.0.norm.running_var\n",
      "Matched and loaded weight for: decoder.input_proj.0.norm.num_batches_tracked\n",
      "Matched and loaded weight for: decoder.input_proj.1.conv.weight\n",
      "Matched and loaded weight for: decoder.input_proj.1.norm.weight\n",
      "Matched and loaded weight for: decoder.input_proj.1.norm.bias\n",
      "Matched and loaded weight for: decoder.input_proj.1.norm.running_mean\n",
      "Matched and loaded weight for: decoder.input_proj.1.norm.running_var\n",
      "Matched and loaded weight for: decoder.input_proj.1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: decoder.input_proj.2.conv.weight\n",
      "Matched and loaded weight for: decoder.input_proj.2.norm.weight\n",
      "Matched and loaded weight for: decoder.input_proj.2.norm.bias\n",
      "Matched and loaded weight for: decoder.input_proj.2.norm.running_mean\n",
      "Matched and loaded weight for: decoder.input_proj.2.norm.running_var\n",
      "Matched and loaded weight for: decoder.input_proj.2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.self_attn.in_proj_weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.self_attn.in_proj_bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.self_attn.out_proj.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.self_attn.out_proj.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.norm1.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.norm1.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.cross_attn.num_points_scale\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.cross_attn.sampling_offsets.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.cross_attn.sampling_offsets.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.cross_attn.attention_weights.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.cross_attn.attention_weights.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.cross_attn.value_proj.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.cross_attn.value_proj.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.cross_attn.output_proj.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.cross_attn.output_proj.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.norm2.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.norm2.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.linear1.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.linear1.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.linear2.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.linear2.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.norm3.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.0.norm3.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.self_attn.in_proj_weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.self_attn.in_proj_bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.self_attn.out_proj.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.self_attn.out_proj.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.norm1.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.norm1.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.cross_attn.num_points_scale\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.cross_attn.sampling_offsets.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.cross_attn.sampling_offsets.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.cross_attn.attention_weights.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.cross_attn.attention_weights.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.cross_attn.value_proj.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.cross_attn.value_proj.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.cross_attn.output_proj.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.cross_attn.output_proj.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.norm2.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.norm2.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.linear1.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.linear1.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.linear2.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.linear2.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.norm3.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.1.norm3.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.self_attn.in_proj_weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.self_attn.in_proj_bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.self_attn.out_proj.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.self_attn.out_proj.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.norm1.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.norm1.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.cross_attn.num_points_scale\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.cross_attn.sampling_offsets.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.cross_attn.sampling_offsets.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.cross_attn.attention_weights.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.cross_attn.attention_weights.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.cross_attn.value_proj.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.cross_attn.value_proj.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.cross_attn.output_proj.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.cross_attn.output_proj.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.norm2.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.norm2.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.linear1.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.linear1.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.linear2.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.linear2.bias\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.norm3.weight\n",
      "Matched and loaded weight for: decoder.decoder.layers.2.norm3.bias\n",
      "Shape mismatch for decoder.denoising_class_embed.weight: torch.Size([81, 256]) vs torch.Size([11, 256])\n",
      "Matched and loaded weight for: decoder.query_pos_head.layers.0.weight\n",
      "Matched and loaded weight for: decoder.query_pos_head.layers.0.bias\n",
      "Matched and loaded weight for: decoder.query_pos_head.layers.1.weight\n",
      "Matched and loaded weight for: decoder.query_pos_head.layers.1.bias\n",
      "Matched and loaded weight for: decoder.enc_output.proj.weight\n",
      "Matched and loaded weight for: decoder.enc_output.proj.bias\n",
      "Matched and loaded weight for: decoder.enc_output.norm.weight\n",
      "Matched and loaded weight for: decoder.enc_output.norm.bias\n",
      "Shape mismatch for decoder.enc_score_head.weight: torch.Size([80, 256]) vs torch.Size([10, 256])\n",
      "Shape mismatch for decoder.enc_score_head.bias: torch.Size([80]) vs torch.Size([10])\n",
      "Matched and loaded weight for: decoder.enc_bbox_head.layers.0.weight\n",
      "Matched and loaded weight for: decoder.enc_bbox_head.layers.0.bias\n",
      "Matched and loaded weight for: decoder.enc_bbox_head.layers.1.weight\n",
      "Matched and loaded weight for: decoder.enc_bbox_head.layers.1.bias\n",
      "Matched and loaded weight for: decoder.enc_bbox_head.layers.2.weight\n",
      "Matched and loaded weight for: decoder.enc_bbox_head.layers.2.bias\n",
      "Shape mismatch for decoder.dec_score_head.0.weight: torch.Size([80, 256]) vs torch.Size([10, 256])\n",
      "Shape mismatch for decoder.dec_score_head.0.bias: torch.Size([80]) vs torch.Size([10])\n",
      "Shape mismatch for decoder.dec_score_head.1.weight: torch.Size([80, 256]) vs torch.Size([10, 256])\n",
      "Shape mismatch for decoder.dec_score_head.1.bias: torch.Size([80]) vs torch.Size([10])\n",
      "Shape mismatch for decoder.dec_score_head.2.weight: torch.Size([80, 256]) vs torch.Size([10, 256])\n",
      "Shape mismatch for decoder.dec_score_head.2.bias: torch.Size([80]) vs torch.Size([10])\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.0.layers.0.weight\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.0.layers.0.bias\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.0.layers.1.weight\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.0.layers.1.bias\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.0.layers.2.weight\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.0.layers.2.bias\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.1.layers.0.weight\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.1.layers.0.bias\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.1.layers.1.weight\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.1.layers.1.bias\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.1.layers.2.weight\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.1.layers.2.bias\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.2.layers.0.weight\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.2.layers.0.bias\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.2.layers.1.weight\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.2.layers.1.bias\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.2.layers.2.weight\n",
      "Matched and loaded weight for: decoder.dec_bbox_head.2.layers.2.bias\n",
      "Matched and loaded weight for: encoder.input_proj.0.conv.weight\n",
      "Matched and loaded weight for: encoder.input_proj.0.norm.weight\n",
      "Matched and loaded weight for: encoder.input_proj.0.norm.bias\n",
      "Matched and loaded weight for: encoder.input_proj.0.norm.running_mean\n",
      "Matched and loaded weight for: encoder.input_proj.0.norm.running_var\n",
      "Matched and loaded weight for: encoder.input_proj.0.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.input_proj.1.conv.weight\n",
      "Matched and loaded weight for: encoder.input_proj.1.norm.weight\n",
      "Matched and loaded weight for: encoder.input_proj.1.norm.bias\n",
      "Matched and loaded weight for: encoder.input_proj.1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.input_proj.1.norm.running_var\n",
      "Matched and loaded weight for: encoder.input_proj.1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.input_proj.2.conv.weight\n",
      "Matched and loaded weight for: encoder.input_proj.2.norm.weight\n",
      "Matched and loaded weight for: encoder.input_proj.2.norm.bias\n",
      "Matched and loaded weight for: encoder.input_proj.2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.input_proj.2.norm.running_var\n",
      "Matched and loaded weight for: encoder.input_proj.2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.self_attn.in_proj_weight\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.self_attn.in_proj_bias\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.self_attn.out_proj.weight\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.self_attn.out_proj.bias\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.linear1.weight\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.linear1.bias\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.linear2.weight\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.linear2.bias\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.norm1.weight\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.norm1.bias\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.norm2.weight\n",
      "Matched and loaded weight for: encoder.encoder.0.layers.0.norm2.bias\n",
      "Matched and loaded weight for: encoder.lateral_convs.0.conv.weight\n",
      "Matched and loaded weight for: encoder.lateral_convs.0.norm.weight\n",
      "Matched and loaded weight for: encoder.lateral_convs.0.norm.bias\n",
      "Matched and loaded weight for: encoder.lateral_convs.0.norm.running_mean\n",
      "Matched and loaded weight for: encoder.lateral_convs.0.norm.running_var\n",
      "Matched and loaded weight for: encoder.lateral_convs.0.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.lateral_convs.1.conv.weight\n",
      "Matched and loaded weight for: encoder.lateral_convs.1.norm.weight\n",
      "Matched and loaded weight for: encoder.lateral_convs.1.norm.bias\n",
      "Matched and loaded weight for: encoder.lateral_convs.1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.lateral_convs.1.norm.running_var\n",
      "Matched and loaded weight for: encoder.lateral_convs.1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.0.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.1.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.bottlenecks.2.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv3.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv3.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv3.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv3.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv3.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.0.conv3.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.0.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.1.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.bottlenecks.2.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv3.conv.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv3.norm.weight\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv3.norm.bias\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv3.norm.running_mean\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv3.norm.running_var\n",
      "Matched and loaded weight for: encoder.fpn_blocks.1.conv3.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.downsample_convs.0.conv.weight\n",
      "Matched and loaded weight for: encoder.downsample_convs.0.norm.weight\n",
      "Matched and loaded weight for: encoder.downsample_convs.0.norm.bias\n",
      "Matched and loaded weight for: encoder.downsample_convs.0.norm.running_mean\n",
      "Matched and loaded weight for: encoder.downsample_convs.0.norm.running_var\n",
      "Matched and loaded weight for: encoder.downsample_convs.0.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.downsample_convs.1.conv.weight\n",
      "Matched and loaded weight for: encoder.downsample_convs.1.norm.weight\n",
      "Matched and loaded weight for: encoder.downsample_convs.1.norm.bias\n",
      "Matched and loaded weight for: encoder.downsample_convs.1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.downsample_convs.1.norm.running_var\n",
      "Matched and loaded weight for: encoder.downsample_convs.1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.0.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.1.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.bottlenecks.2.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv3.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv3.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv3.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv3.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv3.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.0.conv3.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.0.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.1.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv1.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv1.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv1.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv1.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv1.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv1.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv2.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv2.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv2.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv2.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv2.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.bottlenecks.2.conv2.norm.num_batches_tracked\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv3.conv.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv3.norm.weight\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv3.norm.bias\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv3.norm.running_mean\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv3.norm.running_var\n",
      "Matched and loaded weight for: encoder.pan_blocks.1.conv3.norm.num_batches_tracked\n",
      "\n",
      "Load pretrained weights succesfully | 20.094584 million parameters\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "import torch\n",
    "from argparse import Namespace\n",
    "from src.core import YAMLConfig\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "args = Namespace(config_path='configs/rtdetrv2/rtdetrv2_r18vd_120e_coco.yml',\n",
    "                 resume_path='models/rtdetrv2_r18vd_120e_coco_rerun_48.1.pth',\n",
    "                 tuning=None, device=None, seed=0, use_amp=True, output_dir=None,\n",
    "                 summary_dir=None, test_only=False, update=None, print_method='builtin',\n",
    "                 print_rank=0, local_rank=None)\n",
    "\n",
    "\n",
    "def load_pretrained_model(config_path,resume_path):\n",
    "\n",
    "    # initialize the raw model\n",
    "    cfg=YAMLConfig(config_path, resume=resume_path)\n",
    "    model=cfg.model\n",
    "    # model state_dict\n",
    "    state_dict_model=model.state_dict()\n",
    "\n",
    "    # pretrained state_dict\n",
    "    checkpoint=torch.load(args.resume_path,map_location=\"cpu\")\n",
    "    if 'ema' in checkpoint:\n",
    "        state_dict_pretrained=checkpoint['ema']['module']\n",
    "    else:\n",
    "        state_dict_pretrained=checkpoint['model']\n",
    "\n",
    "    # Create a new state dictionary to store matched weights\n",
    "    matched_weights = {}\n",
    "\n",
    "        # Loop through all layers in the model\n",
    "    for model_key, model_param in state_dict_model.items():\n",
    "        # Try to find a matching key in the state_dict\n",
    "        matched_key = None\n",
    "        for state_key in state_dict_pretrained.keys():\n",
    "            # Check if the state_dict key is a substring of the model key\n",
    "            if state_key in model_key:\n",
    "                matched_key = state_key\n",
    "                break\n",
    "\n",
    "        # If a matching key is found and shapes match, load the weight\n",
    "        if matched_key is not None:\n",
    "            state_weight = state_dict_pretrained[matched_key]\n",
    "\n",
    "            # Ensure the shapes match exactly\n",
    "            if state_weight.shape == model_param.shape:\n",
    "                matched_weights[model_key] = state_weight\n",
    "                print(f\"Matched and loaded weight for: {model_key}\")\n",
    "            else:\n",
    "                print(f\"Shape mismatch for {model_key}: {state_weight.shape} vs {model_param.shape}\")\n",
    "\n",
    "    # Load the matched weights into the model\n",
    "    model.load_state_dict(matched_weights, strict=False)\n",
    "    print(f\"\\nLoad pretrained weights succesfully | {sum(p.numel() for p in model.parameters())/1e6} million parameters\")\n",
    "    return model, cfg\n",
    "\n",
    "model, cfg=load_pretrained_model(args.config_path,args.resume_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XexM3tGQXfyL"
   },
   "source": [
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fa03931dfc6a4ba69f65fe5a3398a29f",
      "690d53e82fb5480495fd2a1ba4e04be2",
      "127ba9e807354849863306bec86743b8",
      "1f411e442985453faf0595f8dc721ee3",
      "e324c427549a4798b7c968cb826968eb",
      "f0dc6b04e07e407b99c7699756e3d7b3",
      "d86ac78805d04778aa81a71cf8f595ee",
      "0044f6ec17834d3688ded99cc673869b",
      "b9baa987f36445c685167f3ec7670ec0",
      "ae454599c67346a58631a63b8a05a649",
      "46f751388868434f9cb0c29182592c41"
     ]
    },
    "executionInfo": {
     "elapsed": 40588,
     "status": "ok",
     "timestamp": 1734009881746,
     "user": {
      "displayName": "Tai Do",
      "userId": "13979933527558473981"
     },
     "user_tz": -480
    },
    "id": "-8yowcP2UaL7",
    "outputId": "26288140-38b3-4424-de9a-9e33c8e11af0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa03931dfc6a4ba69f65fe5a3398a29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/841 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pixel_values': tensor([[[[0.3843, 0.4000, 0.4039,  ..., 0.3804, 0.3529, 0.3294],\n",
      "          [0.3804, 0.3922, 0.3961,  ..., 0.3490, 0.3804, 0.3137],\n",
      "          [0.3765, 0.3843, 0.3922,  ..., 0.3098, 0.3804, 0.3373],\n",
      "          ...,\n",
      "          [0.2431, 0.2784, 0.3176,  ..., 0.3176, 0.3098, 0.3059],\n",
      "          [0.2980, 0.3412, 0.3373,  ..., 0.3176, 0.3137, 0.3059],\n",
      "          [0.3451, 0.3451, 0.3176,  ..., 0.3176, 0.3137, 0.3098]],\n",
      "\n",
      "         [[0.5294, 0.5451, 0.5490,  ..., 0.4235, 0.2902, 0.1137],\n",
      "          [0.5255, 0.5373, 0.5412,  ..., 0.3961, 0.3451, 0.1451],\n",
      "          [0.5216, 0.5294, 0.5373,  ..., 0.3686, 0.3882, 0.2431],\n",
      "          ...,\n",
      "          [0.2235, 0.2588, 0.2980,  ..., 0.3020, 0.2941, 0.2902],\n",
      "          [0.2784, 0.3216, 0.3176,  ..., 0.3020, 0.2980, 0.2902],\n",
      "          [0.3255, 0.3255, 0.2980,  ..., 0.3020, 0.2980, 0.2941]],\n",
      "\n",
      "         [[0.6431, 0.6588, 0.6627,  ..., 0.4510, 0.3490, 0.2196],\n",
      "          [0.6392, 0.6510, 0.6549,  ..., 0.4235, 0.3961, 0.2314],\n",
      "          [0.6353, 0.6431, 0.6510,  ..., 0.3882, 0.4235, 0.3059],\n",
      "          ...,\n",
      "          [0.2078, 0.2431, 0.2824,  ..., 0.2902, 0.2824, 0.2784],\n",
      "          [0.2627, 0.3059, 0.3020,  ..., 0.2902, 0.2863, 0.2784],\n",
      "          [0.3098, 0.3098, 0.2824,  ..., 0.2902, 0.2863, 0.2824]]],\n",
      "\n",
      "\n",
      "        [[[0.1686, 0.1686, 0.1725,  ..., 0.8196, 0.8275, 0.8196],\n",
      "          [0.1765, 0.1725, 0.1608,  ..., 0.8314, 0.8196, 0.8196],\n",
      "          [0.1843, 0.1725, 0.1608,  ..., 0.8392, 0.8118, 0.8196],\n",
      "          ...,\n",
      "          [0.3490, 0.3686, 0.1882,  ..., 0.6980, 0.6667, 0.6784],\n",
      "          [0.2157, 0.2353, 0.1137,  ..., 0.7059, 0.6745, 0.6902],\n",
      "          [0.1529, 0.1255, 0.0706,  ..., 0.7098, 0.6863, 0.6941]],\n",
      "\n",
      "         [[0.2431, 0.2431, 0.2471,  ..., 0.8039, 0.8118, 0.8039],\n",
      "          [0.2471, 0.2471, 0.2314,  ..., 0.8157, 0.8039, 0.8039],\n",
      "          [0.2510, 0.2392, 0.2275,  ..., 0.8235, 0.7961, 0.8039],\n",
      "          ...,\n",
      "          [0.3569, 0.3725, 0.2000,  ..., 0.6980, 0.6588, 0.6706],\n",
      "          [0.2275, 0.2431, 0.1216,  ..., 0.7020, 0.6706, 0.6784],\n",
      "          [0.1647, 0.1333, 0.0784,  ..., 0.7059, 0.6784, 0.6824]],\n",
      "\n",
      "         [[0.3020, 0.3020, 0.3059,  ..., 0.7569, 0.7647, 0.7569],\n",
      "          [0.3059, 0.3059, 0.2941,  ..., 0.7686, 0.7569, 0.7569],\n",
      "          [0.3137, 0.3020, 0.2902,  ..., 0.7765, 0.7490, 0.7569],\n",
      "          ...,\n",
      "          [0.3255, 0.3529, 0.1765,  ..., 0.6784, 0.6431, 0.6549],\n",
      "          [0.2000, 0.2235, 0.1059,  ..., 0.6863, 0.6549, 0.6627],\n",
      "          [0.1373, 0.1098, 0.0627,  ..., 0.6902, 0.6667, 0.6706]]],\n",
      "\n",
      "\n",
      "        [[[0.0353, 0.0353, 0.0353,  ..., 0.0510, 0.0471, 0.0510],\n",
      "          [0.0353, 0.0353, 0.0353,  ..., 0.0510, 0.0510, 0.0549],\n",
      "          [0.0353, 0.0353, 0.0353,  ..., 0.0549, 0.0510, 0.0588],\n",
      "          ...,\n",
      "          [0.0824, 0.0784, 0.0863,  ..., 0.0431, 0.0431, 0.0431],\n",
      "          [0.0824, 0.0784, 0.0824,  ..., 0.0431, 0.0431, 0.0471],\n",
      "          [0.0824, 0.0784, 0.0902,  ..., 0.0431, 0.0431, 0.0549]],\n",
      "\n",
      "         [[0.0157, 0.0157, 0.0157,  ..., 0.0353, 0.0314, 0.0353],\n",
      "          [0.0157, 0.0157, 0.0157,  ..., 0.0353, 0.0353, 0.0392],\n",
      "          [0.0157, 0.0157, 0.0157,  ..., 0.0392, 0.0353, 0.0431],\n",
      "          ...,\n",
      "          [0.0902, 0.0824, 0.0902,  ..., 0.0196, 0.0196, 0.0196],\n",
      "          [0.0863, 0.0824, 0.0863,  ..., 0.0196, 0.0196, 0.0235],\n",
      "          [0.0863, 0.0824, 0.0902,  ..., 0.0196, 0.0196, 0.0314]],\n",
      "\n",
      "         [[0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0275, 0.0314],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0353],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0353, 0.0314, 0.0392],\n",
      "          ...,\n",
      "          [0.1529, 0.1569, 0.1686,  ..., 0.0196, 0.0196, 0.0196],\n",
      "          [0.1569, 0.1529, 0.1686,  ..., 0.0196, 0.0196, 0.0235],\n",
      "          [0.1647, 0.1608, 0.1765,  ..., 0.0196, 0.0196, 0.0314]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.3686, 0.3804, 0.3725,  ..., 0.6667, 0.6667, 0.6588],\n",
      "          [0.3725, 0.3765, 0.3686,  ..., 0.6627, 0.6627, 0.6627],\n",
      "          [0.3725, 0.3647, 0.3569,  ..., 0.6588, 0.6588, 0.6667],\n",
      "          ...,\n",
      "          [0.5686, 0.5765, 0.5529,  ..., 0.1961, 0.1765, 0.1765],\n",
      "          [0.5608, 0.5725, 0.5569,  ..., 0.1765, 0.1608, 0.1765],\n",
      "          [0.5569, 0.5725, 0.5608,  ..., 0.1765, 0.1686, 0.2000]],\n",
      "\n",
      "         [[0.4471, 0.4588, 0.4510,  ..., 0.7176, 0.7176, 0.7098],\n",
      "          [0.4510, 0.4549, 0.4431,  ..., 0.7137, 0.7137, 0.7137],\n",
      "          [0.4471, 0.4392, 0.4314,  ..., 0.7098, 0.7098, 0.7176],\n",
      "          ...,\n",
      "          [0.4980, 0.5059, 0.4863,  ..., 0.1647, 0.1451, 0.1412],\n",
      "          [0.4902, 0.5059, 0.4902,  ..., 0.1451, 0.1294, 0.1451],\n",
      "          [0.4863, 0.5059, 0.4980,  ..., 0.1451, 0.1373, 0.1647]],\n",
      "\n",
      "         [[0.4902, 0.5020, 0.4941,  ..., 0.7529, 0.7529, 0.7451],\n",
      "          [0.4980, 0.5020, 0.4902,  ..., 0.7490, 0.7490, 0.7490],\n",
      "          [0.5059, 0.4941, 0.4863,  ..., 0.7451, 0.7451, 0.7529],\n",
      "          ...,\n",
      "          [0.4784, 0.4784, 0.4392,  ..., 0.1216, 0.1020, 0.1059],\n",
      "          [0.4784, 0.4784, 0.4471,  ..., 0.1020, 0.0902, 0.1059],\n",
      "          [0.4745, 0.4784, 0.4549,  ..., 0.1020, 0.0941, 0.1294]]],\n",
      "\n",
      "\n",
      "        [[[0.0431, 0.0353, 0.0235,  ..., 0.0392, 0.0431, 0.0510],\n",
      "          [0.0392, 0.0353, 0.0235,  ..., 0.0588, 0.0549, 0.0510],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0863, 0.0667, 0.0471],\n",
      "          ...,\n",
      "          [0.0353, 0.0431, 0.0431,  ..., 0.1569, 0.1216, 0.1294],\n",
      "          [0.0392, 0.0431, 0.0431,  ..., 0.1451, 0.1216, 0.1333],\n",
      "          [0.0392, 0.0431, 0.0431,  ..., 0.1294, 0.1216, 0.1333]],\n",
      "\n",
      "         [[0.0314, 0.0235, 0.0118,  ..., 0.0314, 0.0353, 0.0431],\n",
      "          [0.0275, 0.0235, 0.0118,  ..., 0.0510, 0.0471, 0.0431],\n",
      "          [0.0196, 0.0196, 0.0196,  ..., 0.0784, 0.0588, 0.0392],\n",
      "          ...,\n",
      "          [0.0275, 0.0353, 0.0353,  ..., 0.0902, 0.0745, 0.0941],\n",
      "          [0.0314, 0.0353, 0.0353,  ..., 0.0784, 0.0706, 0.0941],\n",
      "          [0.0314, 0.0353, 0.0353,  ..., 0.0667, 0.0745, 0.0941]],\n",
      "\n",
      "         [[0.1059, 0.0980, 0.0863,  ..., 0.0824, 0.0863, 0.0941],\n",
      "          [0.1020, 0.0980, 0.0863,  ..., 0.1020, 0.0980, 0.0941],\n",
      "          [0.0941, 0.0941, 0.0941,  ..., 0.1294, 0.1098, 0.0902],\n",
      "          ...,\n",
      "          [0.0824, 0.0902, 0.0902,  ..., 0.0471, 0.0353, 0.0549],\n",
      "          [0.0863, 0.0902, 0.0902,  ..., 0.0353, 0.0314, 0.0588],\n",
      "          [0.0863, 0.0902, 0.0902,  ..., 0.0235, 0.0353, 0.0588]]],\n",
      "\n",
      "\n",
      "        [[[0.3843, 0.5412, 0.9255,  ..., 0.3255, 0.3294, 0.3412],\n",
      "          [0.4941, 0.8196, 0.9843,  ..., 0.3451, 0.3216, 0.3333],\n",
      "          [0.7725, 0.9686, 0.9882,  ..., 0.3529, 0.3373, 0.3294],\n",
      "          ...,\n",
      "          [0.6039, 0.6078, 0.6078,  ..., 0.3373, 0.3373, 0.3333],\n",
      "          [0.6039, 0.6078, 0.6000,  ..., 0.3333, 0.3373, 0.3333],\n",
      "          [0.6118, 0.6118, 0.6078,  ..., 0.3255, 0.3176, 0.3255]],\n",
      "\n",
      "         [[0.3569, 0.5176, 0.9098,  ..., 0.4235, 0.3922, 0.3686],\n",
      "          [0.4784, 0.8078, 0.9804,  ..., 0.4431, 0.3922, 0.3725],\n",
      "          [0.7686, 0.9647, 0.9882,  ..., 0.4588, 0.4157, 0.3843],\n",
      "          ...,\n",
      "          [0.5843, 0.5882, 0.5882,  ..., 0.3490, 0.3490, 0.3451],\n",
      "          [0.5843, 0.5882, 0.5804,  ..., 0.3451, 0.3490, 0.3451],\n",
      "          [0.5922, 0.5922, 0.5882,  ..., 0.3373, 0.3294, 0.3373]],\n",
      "\n",
      "         [[0.4078, 0.5569, 0.9294,  ..., 0.5216, 0.4824, 0.4510],\n",
      "          [0.5176, 0.8353, 0.9843,  ..., 0.5373, 0.4784, 0.4510],\n",
      "          [0.7843, 0.9725, 0.9843,  ..., 0.5490, 0.4980, 0.4588],\n",
      "          ...,\n",
      "          [0.5608, 0.5647, 0.5647,  ..., 0.3843, 0.3843, 0.3804],\n",
      "          [0.5608, 0.5647, 0.5569,  ..., 0.3804, 0.3843, 0.3804],\n",
      "          [0.5686, 0.5686, 0.5647,  ..., 0.3725, 0.3647, 0.3725]]]]), 'labels': [{'size': tensor([640, 640]), 'image_id': tensor([6246]), 'boxes': tensor([[0.9715, 0.8613, 0.0540, 0.0413],\n",
      "        [0.9360, 0.8533, 0.0410, 0.0307],\n",
      "        [0.7600, 0.7390, 0.0500, 0.0540],\n",
      "        [0.5965, 0.6747, 0.0360, 0.0480],\n",
      "        [0.7375, 0.8317, 0.0410, 0.0420],\n",
      "        [0.7297, 0.9133, 0.0475, 0.0627],\n",
      "        [0.8160, 0.9660, 0.0500, 0.0507],\n",
      "        [0.8790, 0.9577, 0.0630, 0.0460],\n",
      "        [0.9172, 0.8943, 0.0515, 0.0367],\n",
      "        [0.8895, 0.8740, 0.0490, 0.0333],\n",
      "        [0.8380, 0.3600, 0.1480, 0.0693],\n",
      "        [0.8165, 0.2993, 0.1370, 0.0813],\n",
      "        [0.6910, 0.2783, 0.0630, 0.1140],\n",
      "        [0.7260, 0.0947, 0.0210, 0.0533],\n",
      "        [0.7437, 0.1550, 0.0245, 0.0553],\n",
      "        [0.7533, 0.1807, 0.0225, 0.0547],\n",
      "        [0.7670, 0.1780, 0.0250, 0.0560],\n",
      "        [0.7785, 0.1697, 0.0240, 0.0580],\n",
      "        [0.3738, 0.0297, 0.0135, 0.0460],\n",
      "        [0.3668, 0.0210, 0.0095, 0.0420],\n",
      "        [0.3427, 0.0240, 0.0115, 0.0453],\n",
      "        [0.3340, 0.0223, 0.0110, 0.0273],\n",
      "        [0.3225, 0.0227, 0.0100, 0.0227],\n",
      "        [0.3142, 0.0360, 0.0215, 0.0480],\n",
      "        [0.3015, 0.0187, 0.0150, 0.0373],\n",
      "        [0.2783, 0.0227, 0.0125, 0.0320],\n",
      "        [0.2673, 0.0420, 0.0175, 0.0547],\n",
      "        [0.2418, 0.0120, 0.0225, 0.0187],\n",
      "        [0.2243, 0.0997, 0.0165, 0.0460],\n",
      "        [0.2298, 0.1037, 0.0145, 0.0300],\n",
      "        [0.3110, 0.0480, 0.0300, 0.0347],\n",
      "        [0.3165, 0.0517, 0.0070, 0.0287],\n",
      "        [0.3305, 0.0540, 0.0110, 0.0333],\n",
      "        [0.3380, 0.0493, 0.0130, 0.0480],\n",
      "        [0.3248, 0.1110, 0.0195, 0.0567],\n",
      "        [0.2862, 0.0997, 0.0165, 0.0500],\n",
      "        [0.2212, 0.0550, 0.0865, 0.0700],\n",
      "        [0.2115, 0.0193, 0.0090, 0.0307],\n",
      "        [0.1797, 0.0227, 0.0255, 0.0360],\n",
      "        [0.1625, 0.0267, 0.0210, 0.0480],\n",
      "        [0.1165, 0.0577, 0.0180, 0.0553],\n",
      "        [0.4715, 0.0423, 0.0170, 0.0500],\n",
      "        [0.5107, 0.1107, 0.0135, 0.0573],\n",
      "        [0.4977, 0.1017, 0.0125, 0.0487],\n",
      "        [0.4820, 0.1333, 0.0180, 0.0573],\n",
      "        [0.4660, 0.1507, 0.0160, 0.0627],\n",
      "        [0.4787, 0.2003, 0.0095, 0.0180],\n",
      "        [0.4822, 0.1783, 0.0115, 0.0340],\n",
      "        [0.4460, 0.2530, 0.0140, 0.0460],\n",
      "        [0.4398, 0.2720, 0.0165, 0.0467],\n",
      "        [0.4083, 0.2567, 0.0185, 0.0627],\n",
      "        [0.4050, 0.3930, 0.0120, 0.0580],\n",
      "        [0.4535, 0.4330, 0.0240, 0.0460],\n",
      "        [0.3995, 0.6510, 0.0330, 0.0527],\n",
      "        [0.5017, 0.6233, 0.0245, 0.0400],\n",
      "        [0.2677, 0.8577, 0.0435, 0.0380],\n",
      "        [0.1463, 0.7400, 0.0425, 0.0520],\n",
      "        [0.0655, 0.7610, 0.0660, 0.0513],\n",
      "        [0.0468, 0.5363, 0.0495, 0.0687],\n",
      "        [0.2090, 0.4603, 0.1020, 0.1993],\n",
      "        [0.2402, 0.5107, 0.0415, 0.0653],\n",
      "        [0.1243, 0.4250, 0.0355, 0.0580],\n",
      "        [0.1445, 0.4020, 0.0420, 0.0613],\n",
      "        [0.1570, 0.3803, 0.0350, 0.0593],\n",
      "        [0.1972, 0.3513, 0.0385, 0.0467],\n",
      "        [0.4182, 0.1587, 0.0685, 0.1107],\n",
      "        [0.3468, 0.1440, 0.0195, 0.0573],\n",
      "        [0.2815, 0.1823, 0.0720, 0.1340],\n",
      "        [0.3665, 0.2237, 0.0110, 0.0460],\n",
      "        [0.3637, 0.2087, 0.0165, 0.0507],\n",
      "        [0.3365, 0.3003, 0.0230, 0.0367],\n",
      "        [0.3070, 0.2927, 0.0270, 0.0680],\n",
      "        [0.3030, 0.2803, 0.0190, 0.0473],\n",
      "        [0.2233, 0.2867, 0.0305, 0.0693],\n",
      "        [0.1727, 0.2323, 0.0215, 0.0513],\n",
      "        [0.2328, 0.2360, 0.0255, 0.0640],\n",
      "        [0.2342, 0.1967, 0.0225, 0.0547]]), 'area': tensor([ 914.2272,  515.0037, 1105.9200,  707.7888,  705.3312, 1219.2427,\n",
      "        1037.6533, 1187.0209,  773.4614,  669.0134, 4203.0420, 4564.0361,\n",
      "        2941.7478,  458.7520,  555.2812,  503.8080,  573.4399,  570.1632,\n",
      "         254.3627,  163.4304,  213.5381,  123.1534,   92.8427,  422.7072,\n",
      "         229.3755,  163.8400,  391.8520,  172.0322,  310.8864,  178.1754,\n",
      "         425.9836,   82.1927,  150.1871,  255.5904,  452.6080,  337.9200,\n",
      "        2480.1299,  113.0496,  376.0128,  412.8762,  407.9618,  348.1606,\n",
      "         317.0304,  249.1727,  422.7072,  410.6915,   70.0418,  160.1536,\n",
      "         263.7824,  315.3914,  474.8636,  285.0816,  452.1984,  711.8842,\n",
      "         401.4076,  677.0691,  905.2164, 1387.7246, 1392.2308, 8327.9873,\n",
      "        1110.5614,  843.3661, 1055.1294,  850.6019,  735.9149, 3105.0410,\n",
      "         457.9335, 3951.8193,  207.2570,  342.4256,  345.4294,  752.0262,\n",
      "         368.3669,  866.1672,  452.0614,  668.4672,  503.8089]), 'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0]), 'orig_size': tensor([1500, 2000]), 'labels': tensor([1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 5, 5, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1,\n",
      "        1, 2, 1, 0, 1, 1, 3, 2, 1, 1, 1, 1, 5, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
      "        1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 4, 1, 1, 1, 1, 1, 4, 1, 5, 3, 2, 2, 3,\n",
      "        2, 1, 1, 1, 1])}, {'size': tensor([640, 640]), 'image_id': tensor([3903]), 'boxes': tensor([[0.2734, 0.8379, 0.0383, 0.1385],\n",
      "        [0.3456, 0.6110, 0.0393, 0.1369],\n",
      "        [0.3667, 0.3455, 0.0335, 0.1108],\n",
      "        [0.4174, 0.3255, 0.0316, 0.1046],\n",
      "        [0.4265, 0.0932, 0.0287, 0.0985],\n",
      "        [0.3854, 0.0686, 0.0325, 0.0923],\n",
      "        [0.3361, 0.0320, 0.0335, 0.0639],\n",
      "        [0.2753, 0.1039, 0.0345, 0.0954],\n",
      "        [0.7860, 0.1917, 0.0775, 0.0585],\n",
      "        [0.7913, 0.1193, 0.0766, 0.0523],\n",
      "        [0.9157, 0.7425, 0.0938, 0.0892],\n",
      "        [0.2872, 0.5533, 0.0354, 0.1139],\n",
      "        [0.3045, 0.3717, 0.0316, 0.1108],\n",
      "        [0.4184, 0.8336, 0.0737, 0.3329],\n",
      "        [0.3351, 0.8851, 0.0718, 0.2298]]), 'area': tensor([ 2172.0989,  2201.6616,  1520.4707,  1353.9420,  1158.4539,  1230.8563,\n",
      "          877.5750,  1346.7013,  1857.1439,  1641.1416,  3429.5044,  1652.0022,\n",
      "         1433.5854, 10050.8984,  6757.9556]), 'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'orig_size': tensor([ 788, 1400]), 'labels': tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 6, 6, 6])}, {'size': tensor([640, 640]), 'image_id': tensor([2128]), 'boxes': tensor([[0.4157, 0.7524, 0.0300, 0.0952],\n",
      "        [0.3414, 0.8614, 0.0286, 0.0962],\n",
      "        [0.8221, 0.3395, 0.0343, 0.0257],\n",
      "        [0.8650, 0.3262, 0.0329, 0.0238],\n",
      "        [0.8593, 0.3652, 0.0243, 0.0352],\n",
      "        [0.7614, 0.3905, 0.0329, 0.0343],\n",
      "        [0.8007, 0.4633, 0.0271, 0.0333],\n",
      "        [0.7639, 0.5257, 0.0764, 0.0781],\n",
      "        [0.6707, 0.5157, 0.0643, 0.0714],\n",
      "        [0.7382, 0.6152, 0.0721, 0.0933],\n",
      "        [0.5850, 0.9386, 0.0500, 0.1133],\n",
      "        [0.4464, 0.9105, 0.0443, 0.1276],\n",
      "        [0.5054, 0.6771, 0.0350, 0.0762],\n",
      "        [0.5454, 0.4048, 0.0021, 0.0114],\n",
      "        [0.5486, 0.4038, 0.0029, 0.0133],\n",
      "        [0.5521, 0.4052, 0.0029, 0.0124],\n",
      "        [0.5557, 0.4081, 0.0043, 0.0105],\n",
      "        [0.2536, 0.1238, 0.0100, 0.0152],\n",
      "        [0.2518, 0.1495, 0.0093, 0.0133],\n",
      "        [0.2493, 0.1952, 0.0114, 0.0229],\n",
      "        [0.2650, 0.1986, 0.0200, 0.0143],\n",
      "        [0.3018, 0.1695, 0.0221, 0.0514],\n",
      "        [0.9007, 0.3376, 0.0186, 0.0257],\n",
      "        [0.8843, 0.3414, 0.0157, 0.0238],\n",
      "        [0.3764, 0.4490, 0.0057, 0.0200],\n",
      "        [0.3289, 0.7710, 0.0279, 0.0829],\n",
      "        [0.3214, 0.6967, 0.0243, 0.0790],\n",
      "        [0.3443, 0.6100, 0.0229, 0.0600],\n",
      "        [0.3379, 0.5524, 0.0186, 0.0533],\n",
      "        [0.3464, 0.1729, 0.0114, 0.0124],\n",
      "        [0.3386, 0.1467, 0.0114, 0.0190],\n",
      "        [0.3314, 0.1238, 0.0086, 0.0190],\n",
      "        [0.3079, 0.0557, 0.0071, 0.0105],\n",
      "        [0.2950, 0.0167, 0.0057, 0.0086],\n",
      "        [0.2996, 0.0276, 0.0064, 0.0114],\n",
      "        [0.3171, 0.0795, 0.0086, 0.0124],\n",
      "        [0.2379, 0.1014, 0.0086, 0.0124],\n",
      "        [0.2596, 0.2976, 0.0193, 0.0238],\n",
      "        [0.2464, 0.3476, 0.0229, 0.0286],\n",
      "        [0.3021, 0.2871, 0.0129, 0.0295],\n",
      "        [0.3207, 0.4162, 0.0529, 0.0362],\n",
      "        [0.3086, 0.5614, 0.0200, 0.0581],\n",
      "        [0.3150, 0.6248, 0.0214, 0.0571],\n",
      "        [0.1757, 0.8048, 0.0286, 0.0819],\n",
      "        [0.2325, 0.4343, 0.0050, 0.0190],\n",
      "        [0.1786, 0.4452, 0.0514, 0.0352],\n",
      "        [0.2096, 0.3319, 0.0421, 0.0314],\n",
      "        [0.2036, 0.0219, 0.0114, 0.0076],\n",
      "        [0.2075, 0.0081, 0.0107, 0.0067],\n",
      "        [0.2018, 0.1195, 0.0093, 0.0086],\n",
      "        [0.2000, 0.1362, 0.0114, 0.0095],\n",
      "        [0.2000, 0.1610, 0.0086, 0.0133],\n",
      "        [0.2000, 0.1805, 0.0086, 0.0143],\n",
      "        [0.2000, 0.2048, 0.0071, 0.0114],\n",
      "        [0.1829, 0.0024, 0.0086, 0.0048],\n",
      "        [0.1829, 0.0071, 0.0100, 0.0048],\n",
      "        [0.1832, 0.0138, 0.0107, 0.0048],\n",
      "        [0.1804, 0.0181, 0.0136, 0.0057],\n",
      "        [0.1800, 0.0210, 0.0114, 0.0057],\n",
      "        [0.1789, 0.0276, 0.0136, 0.0076],\n",
      "        [0.1796, 0.0329, 0.0121, 0.0067],\n",
      "        [0.1782, 0.0410, 0.0107, 0.0057],\n",
      "        [0.1761, 0.0457, 0.0107, 0.0057],\n",
      "        [0.1732, 0.0533, 0.0121, 0.0057],\n",
      "        [0.1739, 0.0576, 0.0136, 0.0086],\n",
      "        [0.1757, 0.0648, 0.0114, 0.0076],\n",
      "        [0.1764, 0.0776, 0.0200, 0.0086],\n",
      "        [0.1732, 0.0843, 0.0136, 0.0067],\n",
      "        [0.1711, 0.0910, 0.0093, 0.0067],\n",
      "        [0.1700, 0.0967, 0.0171, 0.0067],\n",
      "        [0.1686, 0.1033, 0.0171, 0.0086],\n",
      "        [0.1682, 0.1138, 0.0179, 0.0105],\n",
      "        [0.1679, 0.1190, 0.0157, 0.0076],\n",
      "        [0.1646, 0.1276, 0.0164, 0.0095],\n",
      "        [0.1686, 0.1362, 0.0171, 0.0095],\n",
      "        [0.1700, 0.1410, 0.0143, 0.0076],\n",
      "        [0.1664, 0.1495, 0.0171, 0.0095],\n",
      "        [0.1589, 0.1700, 0.0250, 0.0124],\n",
      "        [0.1689, 0.0257, 0.0021, 0.0076],\n",
      "        [0.1632, 0.0257, 0.0021, 0.0057],\n",
      "        [0.1614, 0.0529, 0.0043, 0.0105],\n",
      "        [0.1596, 0.9438, 0.0579, 0.1105],\n",
      "        [0.1254, 0.3643, 0.0264, 0.0333],\n",
      "        [0.1229, 0.3386, 0.0329, 0.0219],\n",
      "        [0.1361, 0.3210, 0.0350, 0.0210],\n",
      "        [0.1411, 0.3010, 0.0321, 0.0248],\n",
      "        [0.1564, 0.2505, 0.0243, 0.0152],\n",
      "        [0.1557, 0.2390, 0.0243, 0.0133],\n",
      "        [0.1568, 0.2314, 0.0264, 0.0133],\n",
      "        [0.1546, 0.2148, 0.0279, 0.0124],\n",
      "        [0.1543, 0.2052, 0.0257, 0.0105],\n",
      "        [0.1554, 0.1995, 0.0264, 0.0162],\n",
      "        [0.1571, 0.1900, 0.0229, 0.0124],\n",
      "        [0.1564, 0.1829, 0.0243, 0.0133],\n",
      "        [0.1486, 0.1019, 0.0029, 0.0076],\n",
      "        [0.1364, 0.1929, 0.0029, 0.0105],\n",
      "        [0.1421, 0.1924, 0.0029, 0.0095],\n",
      "        [0.1289, 0.2071, 0.0050, 0.0143],\n",
      "        [0.1279, 0.2400, 0.0057, 0.0114],\n",
      "        [0.1364, 0.2405, 0.0057, 0.0124],\n",
      "        [0.0775, 0.2890, 0.0307, 0.0200],\n",
      "        [0.0975, 0.3667, 0.0179, 0.0324],\n",
      "        [0.0729, 0.3671, 0.0171, 0.0352],\n",
      "        [0.0904, 0.4686, 0.0536, 0.0286],\n",
      "        [0.0489, 0.3781, 0.0236, 0.0400],\n",
      "        [0.0157, 0.3852, 0.0271, 0.0429],\n",
      "        [0.3021, 0.3310, 0.0071, 0.0067],\n",
      "        [0.3386, 0.4729, 0.0057, 0.0124],\n",
      "        [0.2011, 0.5452, 0.0064, 0.0124],\n",
      "        [0.2179, 0.5562, 0.0057, 0.0114],\n",
      "        [0.2200, 0.5810, 0.0071, 0.0114],\n",
      "        [0.2614, 0.6333, 0.0071, 0.0114],\n",
      "        [0.2925, 0.6238, 0.0064, 0.0076],\n",
      "        [0.2054, 0.6233, 0.0050, 0.0143],\n",
      "        [0.1961, 0.6724, 0.0079, 0.0152],\n",
      "        [0.4661, 0.4238, 0.0079, 0.0171],\n",
      "        [0.3754, 0.2929, 0.0036, 0.0105],\n",
      "        [0.4018, 0.3024, 0.0050, 0.0124]]), 'area': tensor([1170.2874, 1125.7035,  361.1168,  320.4354,  350.5284,  461.4269,\n",
      "         370.5905, 2444.7827, 1880.8164, 2757.9734, 2321.0667, 2314.9368,\n",
      "        1092.2667,   10.0310,   15.6038,   14.4893,   18.3902,   62.4152,\n",
      "          50.7125,  106.9978,  117.0285,  466.4429,  195.6051,  153.2517,\n",
      "          46.8111,  945.4230,  786.3212,  561.7366,  405.6995,   57.9571,\n",
      "          89.1648,   66.8736,   30.6502,   20.0621,   30.0932,   43.4679,\n",
      "          43.4679,  188.0818,  267.4936,  155.4814,  783.5345,  475.9172,\n",
      "         501.5510,  958.5198,   39.0095,  742.2961,  542.5105,   35.6659,\n",
      "          29.2571,   32.6010,   44.5824,   46.8116,   50.1552,   33.4366,\n",
      "          16.7184,   19.5047,   20.8980,   31.7649,   26.7494,   42.3532,\n",
      "          33.1582,   25.0776,   25.0776,   28.4212,   47.6474,   35.6657,\n",
      "          70.2171,   37.0591,   25.3563,   46.8114,   60.1860,   76.6258,\n",
      "          49.0406,   64.0872,   66.8734,   44.5824,   66.8736,  126.7808,\n",
      "           6.6873,    5.0155,   18.3901, 2618.0969,  360.8383,  294.8010,\n",
      "         300.3736,  326.0084,  151.5797,  132.6324,  144.3353,  141.2702,\n",
      "         110.3412,  175.2643,  115.9140,  132.6322,    8.9165,   12.2602,\n",
      "          11.1456,   29.2575,   26.7494,   28.9786,  251.6114,  236.8432,\n",
      "         247.4323,  626.9385,  386.1943,  476.4739,   19.5049,   28.9785,\n",
      "          32.6009,   26.7494,   33.4367,   33.4366,   20.0620,   29.2571,\n",
      "          49.0405,   55.1706,   15.3250,   25.3562]), 'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'orig_size': tensor([1050, 1400]), 'labels': tensor([4, 4, 4, 4, 5, 4, 0, 0, 0, 0, 4, 4, 4, 1, 1, 1, 1, 4, 4, 6, 4, 6, 4, 4,\n",
      "        1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 6, 4, 1, 4, 0, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 1, 1, 6, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1,\n",
      "        1, 1, 1, 1, 4, 5, 5, 4, 5, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])}, {'size': tensor([640, 640]), 'image_id': tensor([2829]), 'boxes': tensor([[0.0750, 0.6681, 0.0157, 0.0419],\n",
      "        [0.1232, 0.6916, 0.0236, 0.0406],\n",
      "        [0.1875, 0.6104, 0.0164, 0.0508],\n",
      "        [0.1861, 0.5933, 0.0150, 0.0444],\n",
      "        [0.3132, 0.4911, 0.0121, 0.0406],\n",
      "        [0.4704, 0.8636, 0.0950, 0.1358],\n",
      "        [0.6639, 0.6307, 0.1479, 0.2107],\n",
      "        [0.6525, 0.3782, 0.0093, 0.0406],\n",
      "        [0.6636, 0.3813, 0.0114, 0.0444],\n",
      "        [0.7100, 0.3585, 0.0100, 0.0419],\n",
      "        [0.8257, 0.1218, 0.0129, 0.0381],\n",
      "        [0.8054, 0.1142, 0.0121, 0.0381],\n",
      "        [0.7971, 0.1072, 0.0129, 0.0393],\n",
      "        [0.8471, 0.0907, 0.0143, 0.0419],\n",
      "        [0.7054, 0.1136, 0.0550, 0.0622],\n",
      "        [0.6221, 0.0476, 0.0571, 0.0799]]), 'area': tensor([  269.5520,   392.0754,   341.5809,   272.8934,   201.9782,  5283.7358,\n",
      "        12758.0459,   154.4539,   207.9196,   171.5322,   200.4931,   189.3546,\n",
      "          207.1762,   245.0471,  1400.8528,  1871.2690]), 'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'orig_size': tensor([ 788, 1400]), 'labels': tensor([1, 1, 1, 1, 1, 4, 6, 1, 1, 1, 1, 1, 1, 1, 4, 5])}, {'size': tensor([640, 640]), 'image_id': tensor([5041]), 'boxes': tensor([[0.4464, 0.0276, 0.0271, 0.0229],\n",
      "        [0.3911, 0.1062, 0.0293, 0.0219],\n",
      "        [0.3882, 0.0310, 0.0279, 0.0200],\n",
      "        [0.3861, 0.0062, 0.0279, 0.0124],\n",
      "        [0.0625, 0.2105, 0.0336, 0.0229],\n",
      "        [0.3954, 0.2438, 0.0264, 0.0229],\n",
      "        [0.7214, 0.3314, 0.0186, 0.1162],\n",
      "        [0.7479, 0.4076, 0.0157, 0.0343],\n",
      "        [0.6029, 0.7405, 0.0143, 0.0429],\n",
      "        [0.4600, 0.6110, 0.0329, 0.0200],\n",
      "        [0.8457, 0.9124, 0.0286, 0.0190],\n",
      "        [0.8496, 0.9890, 0.0279, 0.0219],\n",
      "        [0.9111, 0.9224, 0.0321, 0.0219],\n",
      "        [0.9136, 0.9595, 0.0300, 0.0219],\n",
      "        [0.8957, 0.8862, 0.0086, 0.0124],\n",
      "        [0.9025, 0.8843, 0.0079, 0.0105],\n",
      "        [0.7879, 0.6800, 0.0100, 0.0114],\n",
      "        [0.5975, 0.8686, 0.0221, 0.0800]]), 'area': tensor([254.1192, 262.7570, 228.2057, 141.2702, 314.3052, 247.4318, 883.8402,\n",
      "        220.6824, 250.7755, 269.1657, 222.9116, 249.9396, 288.3918, 269.1657,\n",
      "         43.4678,  33.7154,  46.8114, 725.5771]), 'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'orig_size': tensor([1050, 1400]), 'labels': tensor([4, 4, 4, 4, 4, 5, 6, 4, 4, 4, 4, 5, 4, 4, 1, 1, 1, 6])}, {'size': tensor([640, 640]), 'image_id': tensor([2992]), 'boxes': tensor([[0.5589, 0.6770, 0.0136, 0.0266],\n",
      "        [0.5893, 0.5412, 0.0286, 0.0571],\n",
      "        [0.5982, 0.4772, 0.0164, 0.0152],\n",
      "        [0.5639, 0.4556, 0.0136, 0.0152],\n",
      "        [0.5721, 0.4353, 0.0100, 0.0152],\n",
      "        [0.5482, 0.4416, 0.0107, 0.0178],\n",
      "        [0.5339, 0.4188, 0.0064, 0.0178],\n",
      "        [0.6657, 0.4581, 0.0114, 0.0178],\n",
      "        [0.5711, 0.4689, 0.0136, 0.0140],\n",
      "        [0.5400, 0.4308, 0.0071, 0.0140],\n",
      "        [0.6579, 0.4556, 0.0086, 0.0178],\n",
      "        [0.6796, 0.4607, 0.0121, 0.0102],\n",
      "        [0.6900, 0.4549, 0.0114, 0.0140],\n",
      "        [0.6779, 0.4499, 0.0100, 0.0140],\n",
      "        [0.6996, 0.4397, 0.0121, 0.0190],\n",
      "        [0.6482, 0.4499, 0.0164, 0.0216],\n",
      "        [0.6625, 0.4404, 0.0150, 0.0203],\n",
      "        [0.7214, 0.4365, 0.0171, 0.0203],\n",
      "        [0.6957, 0.4327, 0.0457, 0.0457],\n",
      "        [0.7404, 0.4207, 0.0150, 0.0165],\n",
      "        [0.7250, 0.4232, 0.0157, 0.0114],\n",
      "        [0.5336, 0.9867, 0.0129, 0.0241],\n",
      "        [0.3668, 0.7316, 0.0064, 0.0266],\n",
      "        [0.4264, 0.7652, 0.0057, 0.0228],\n",
      "        [0.6661, 0.4778, 0.0107, 0.0114]]), 'area': tensor([148.1421, 668.3108, 102.4743,  84.6526,  62.3756,  77.9695,  46.7817,\n",
      "         83.1675,  77.5983,  40.8412,  62.3756,  50.4946,  65.3459,  57.1777,\n",
      "         94.6773, 145.1719, 124.7513, 142.5729, 855.4373, 101.3604,  73.5141,\n",
      "        126.9790,  70.1728,  53.4648,  50.1233]), 'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0]), 'orig_size': tensor([ 788, 1400]), 'labels': tensor([4, 9, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 5, 9, 9, 9, 0, 4, 4, 4, 1, 1,\n",
      "        0])}, {'size': tensor([640, 640]), 'image_id': tensor([2748]), 'boxes': tensor([[9.4258e-01, 6.3177e-03, 4.6399e-02, 1.2635e-02],\n",
      "        [5.0980e-02, 7.1965e-01, 8.3308e-02, 5.8879e-02],\n",
      "        [2.0336e-01, 6.2339e-01, 6.9599e-02, 4.7664e-02],\n",
      "        [2.3710e-01, 6.9255e-01, 6.3272e-02, 2.8972e-02],\n",
      "        [2.2920e-01, 7.2620e-01, 8.1199e-02, 3.2711e-02],\n",
      "        [2.2867e-01, 7.5891e-01, 7.8035e-02, 2.7103e-02],\n",
      "        [2.2287e-01, 7.8648e-01, 1.1705e-01, 4.1122e-02],\n",
      "        [6.8950e-01, 5.8460e-01, 5.4836e-02, 6.3552e-02],\n",
      "        [6.4679e-01, 5.4255e-01, 4.5345e-02, 5.2337e-02],\n",
      "        [7.5857e-01, 4.5844e-01, 4.5345e-02, 4.8599e-02],\n",
      "        [9.4258e-01, 1.5329e-01, 4.6399e-02, 4.5795e-02],\n",
      "        [5.0980e-02, 8.9629e-01, 8.3308e-02, 5.8879e-02],\n",
      "        [2.0336e-01, 9.8436e-01, 6.9599e-02, 3.1278e-02],\n",
      "        [2.3710e-01, 9.2339e-01, 6.3272e-02, 2.8972e-02],\n",
      "        [2.2920e-01, 8.8975e-01, 8.1199e-02, 3.2711e-02],\n",
      "        [2.2867e-01, 8.5704e-01, 7.8035e-02, 2.7103e-02],\n",
      "        [2.2287e-01, 8.2947e-01, 1.1705e-01, 4.1122e-02],\n",
      "        [6.8950e-01, 9.9978e-01, 5.4836e-02, 4.3688e-04]]), 'area': tensor([ 240.1382, 2009.1289, 1358.7964,  750.8506, 1087.9250,  866.3025,\n",
      "        1971.5868, 1427.4235,  972.0692,  902.6365,  870.3414, 2009.1289,\n",
      "         891.6750,  750.8506, 1087.9250,  866.3050, 1971.5868,    9.8120]), 'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'orig_size': tensor([ 788, 1400]), 'labels': tensor([6, 4, 4, 4, 5, 4, 6, 4, 4, 4, 6, 4, 4, 4, 5, 4, 6, 4])}, {'size': tensor([640, 640]), 'image_id': tensor([3715]), 'boxes': tensor([[0.0267, 0.0483, 0.0320, 0.0536],\n",
      "        [0.0010, 0.1432, 0.0021, 0.0304],\n",
      "        [0.0149, 0.0459, 0.0297, 0.0556],\n",
      "        [0.0586, 0.0483, 0.0320, 0.0536],\n",
      "        [0.1066, 0.1432, 0.0467, 0.0304],\n",
      "        [0.1465, 0.1425, 0.0344, 0.0318],\n",
      "        [0.1825, 0.1422, 0.0363, 0.0311],\n",
      "        [0.2184, 0.1462, 0.0307, 0.0245],\n",
      "        [0.2762, 0.1475, 0.0320, 0.0218],\n",
      "        [0.0832, 0.0459, 0.0553, 0.0556],\n",
      "        [0.1404, 0.0344, 0.0529, 0.0589],\n",
      "        [0.2006, 0.0423, 0.0442, 0.0562],\n",
      "        [0.2433, 0.0496, 0.0436, 0.0615],\n",
      "        [0.2833, 0.0370, 0.0363, 0.0628],\n",
      "        [0.3244, 0.0436, 0.0375, 0.0523],\n",
      "        [0.2977, 0.0015, 0.0393, 0.0029],\n",
      "        [0.3419, 0.0045, 0.0406, 0.0089],\n",
      "        [0.4750, 0.1247, 0.0694, 0.0450],\n",
      "        [0.4415, 0.0273, 0.0467, 0.0545],\n",
      "        [0.5082, 0.1187, 0.0080, 0.0225],\n",
      "        [0.4885, 0.0797, 0.0104, 0.0278],\n",
      "        [0.5063, 0.0770, 0.0092, 0.0265],\n",
      "        [0.6265, 0.0074, 0.0492, 0.0149],\n",
      "        [0.7377, 0.1224, 0.0111, 0.0258],\n",
      "        [0.7187, 0.1326, 0.0184, 0.0318],\n",
      "        [0.0267, 0.2685, 0.0320, 0.0536],\n",
      "        [0.0210, 0.3562, 0.0420, 0.0648],\n",
      "        [0.0010, 0.1736, 0.0021, 0.0304],\n",
      "        [0.0149, 0.2709, 0.0297, 0.0556],\n",
      "        [0.0161, 0.5345, 0.0322, 0.0893],\n",
      "        [0.0213, 0.6430, 0.0426, 0.1793],\n",
      "        [0.0586, 0.2685, 0.0320, 0.0536],\n",
      "        [0.0657, 0.3562, 0.0449, 0.0648],\n",
      "        [0.1066, 0.1736, 0.0467, 0.0304],\n",
      "        [0.1465, 0.1743, 0.0344, 0.0318],\n",
      "        [0.1825, 0.1746, 0.0363, 0.0311],\n",
      "        [0.2184, 0.1706, 0.0307, 0.0245],\n",
      "        [0.2762, 0.1693, 0.0320, 0.0218],\n",
      "        [0.0832, 0.2709, 0.0553, 0.0556],\n",
      "        [0.1404, 0.2824, 0.0529, 0.0589],\n",
      "        [0.2006, 0.2745, 0.0442, 0.0562],\n",
      "        [0.2433, 0.2672, 0.0436, 0.0615],\n",
      "        [0.2833, 0.2798, 0.0363, 0.0628],\n",
      "        [0.3244, 0.2732, 0.0375, 0.0523],\n",
      "        [0.2519, 0.3522, 0.0473, 0.0622],\n",
      "        [0.1520, 0.3575, 0.0676, 0.0767],\n",
      "        [0.2977, 0.3496, 0.0393, 0.0714],\n",
      "        [0.3419, 0.3522, 0.0406, 0.0886],\n",
      "        [0.4750, 0.1921, 0.0694, 0.0450],\n",
      "        [0.4415, 0.2996, 0.0467, 0.0748],\n",
      "        [0.5082, 0.1981, 0.0080, 0.0225],\n",
      "        [0.4885, 0.2371, 0.0104, 0.0278],\n",
      "        [0.5063, 0.2398, 0.0092, 0.0265],\n",
      "        [0.4750, 0.4508, 0.0621, 0.1191],\n",
      "        [0.5638, 0.4696, 0.0160, 0.0232],\n",
      "        [0.6265, 0.3628, 0.0492, 0.1217],\n",
      "        [0.5988, 0.4941, 0.0147, 0.0205],\n",
      "        [0.6225, 0.4868, 0.0141, 0.0126],\n",
      "        [0.6465, 0.4726, 0.0363, 0.0767],\n",
      "        [0.6492, 0.6119, 0.0516, 0.1158],\n",
      "        [0.8763, 0.7409, 0.0535, 0.1250],\n",
      "        [0.7973, 0.4743, 0.0627, 0.0748],\n",
      "        [0.7012, 0.7911, 0.0940, 0.1237],\n",
      "        [0.7694, 0.4061, 0.0633, 0.0668],\n",
      "        [0.7377, 0.1945, 0.0111, 0.0258],\n",
      "        [0.7187, 0.1842, 0.0184, 0.0318],\n",
      "        [0.2120, 0.5434, 0.0584, 0.0847],\n",
      "        [0.0890, 0.5345, 0.0719, 0.0893],\n",
      "        [0.1708, 0.6641, 0.0867, 0.1303],\n",
      "        [0.0915, 0.6430, 0.0977, 0.1793],\n",
      "        [0.9298, 0.7409, 0.0535, 0.1250],\n",
      "        [0.9887, 0.4743, 0.0226, 0.0748],\n",
      "        [0.0213, 0.9867, 0.0426, 0.0266],\n",
      "        [0.8763, 0.9513, 0.0535, 0.0974],\n",
      "        [0.7012, 0.9148, 0.0940, 0.1237],\n",
      "        [0.1708, 0.9884, 0.0867, 0.0233],\n",
      "        [0.0915, 0.9867, 0.0977, 0.0266],\n",
      "        [0.9298, 0.9513, 0.0535, 0.0974]]), 'area': tensor([ 701.3832,   26.0363,  676.9910,  701.3833,  582.1548,  447.6064,\n",
      "         461.7605,  308.0626,  285.7487, 1258.8929, 1274.5458, 1019.1040,\n",
      "        1099.5328,  933.3464,  802.4614,   47.4735,  147.8701, 1279.5422,\n",
      "        1043.5063,   73.6018,  118.8957,   99.9119,  299.1309,  116.8972,\n",
      "         239.7893,  701.3834, 1116.2020,   26.0363,  676.9910, 1177.9418,\n",
      "        3131.7683,  701.3834, 1191.2855,  582.1548,  447.6062,  461.7603,\n",
      "         308.0623,  285.7485, 1258.8929, 1274.5455, 1019.1043, 1099.5330,\n",
      "         933.3464,  802.4611, 1205.2736, 2124.7979, 1150.9880, 1472.7050,\n",
      "        1279.5424, 1430.0753,   73.6018,  118.8957,   99.9119, 3027.3379,\n",
      "         151.5335, 2451.1765,  123.8912,   72.7696, 1139.6631, 2447.8477,\n",
      "        2738.0896, 1919.3110, 4764.3105, 1732.3104,  116.8972,  239.7892,\n",
      "        2024.8862, 2630.1863, 4625.4351, 7175.1904, 2738.0896,  692.0475,\n",
      "         464.7869, 2132.8020, 4764.3105,  826.9268, 1064.8728, 2132.8020]), 'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0]), 'orig_size': tensor([1050, 1400]), 'labels': tensor([4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 6, 1, 1, 1, 6, 3,\n",
      "        7, 4, 4, 4, 4, 5, 6, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5,\n",
      "        5, 6, 1, 1, 1, 6, 1, 6, 1, 1, 7, 4, 4, 4, 6, 4, 3, 7, 4, 5, 6, 6, 4, 4,\n",
      "        6, 4, 6, 6, 6, 4])}]}\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from data_visdrone import VisDroneData\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Extract pixel values and labels\n",
    "    pixel_values = torch.stack([x[\"pixel_values\"] for x in batch])\n",
    "\n",
    "    # Prepare labels\n",
    "    labels = [x[\"labels\"] for x in batch]\n",
    "\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# dataloaders\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.1,\n",
    "            scale_limit=0.5,\n",
    "            rotate_limit=0,\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.HueSaturationValue(\n",
    "            hue_shift_limit=15, sat_shift_limit=70, val_shift_limit=40, p=0.5\n",
    "        ),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(\n",
    "        format=\"pascal_voc\",  # Albumentations expects [xmin, ymin, xmax, ymax]\n",
    "        label_fields=[\"category\"],\n",
    "        clip=True,\n",
    "        min_area=1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "val_transform = A.Compose(\n",
    "    [A.NoOp()],\n",
    "    bbox_params=A.BboxParams(\n",
    "        format=\"pascal_voc\",\n",
    "        label_fields=[\"category\"],\n",
    "        clip=True,\n",
    "        min_area=1,\n",
    "    ),\n",
    ")\n",
    "\n",
    "ds_train = VisDroneData(\n",
    "        json_path=\"dataset/visdrone/annotations/train_coco.json\",\n",
    "        split=\"train\",\n",
    "        transforms=train_transform)\n",
    "train_loader=DataLoader(ds_train,\n",
    "                        batch_size=8,\n",
    "                        collate_fn=collate_fn,\n",
    "                        num_workers=2,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True)\n",
    "\n",
    "ds_val = VisDroneData(\n",
    "        json_path=\"dataset/visdrone/annotations/val_coco.json\",\n",
    "        split=\"val\",\n",
    "        transforms=train_transform)\n",
    "val_loader=DataLoader(ds_val,\n",
    "                      batch_size=8,\n",
    "                      collate_fn=collate_fn,\n",
    "                      num_workers=2,\n",
    "                      shuffle=False,\n",
    "                      pin_memory=True)\n",
    "\n",
    "# take a batch\n",
    "batch=next(iter(train_loader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qz_HNia3Xhuj"
   },
   "source": [
    "## 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5012,
     "status": "ok",
     "timestamp": 1734009886747,
     "user": {
      "displayName": "Tai Do",
      "userId": "13979933527558473981"
     },
     "user_tz": -480
    },
    "id": "Ycjfo3QNXi0T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "from transformers import get_scheduler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "\n",
    "from dataclasses import dataclass, replace\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "error",
     "timestamp": 1734009886748,
     "user": {
      "displayName": "Tai Do",
      "userId": "13979933527558473981"
     },
     "user_tz": -480
    },
    "id": "6ZUrH3LWX0lI",
    "outputId": "527c929e-3a20-4823-ae54-8f7a98727d7a"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8eb927792ac3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# train 1 epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m def train_one_epoch(\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "model=model.to(\"cuda\")\n",
    "# train 1 epoch\n",
    "def train_one_epoch(\n",
    "    model,loader,optimizer,criterion,\n",
    "    max_norm=0.1,\n",
    "    device=\"cuda\",\n",
    "    lr_warmup_scheduler=None, # learning rate warmup: start with small lr till reaching actual lr\n",
    "    amp=True,\n",
    "    scaler=None):\n",
    "\n",
    "  model.train()\n",
    "  loss_total=0\n",
    "  num_batches=0\n",
    "\n",
    "  if scaler is None:\n",
    "    scaler=GradScaler(enabled=True) # use GradeScaler if scaler is not provided\n",
    "\n",
    "  # tqdm progress bar\n",
    "  progress_bar=tqdm(loader,desc=\"Training\",leave =True)\n",
    "  for batch_idx, batch in enumerate(progress_bar):\n",
    "    batch_images = batch[\"pixel_values\"].to(device)\n",
    "\n",
    "    batch_images = batch_images.to(device=device, dtype=torch.float32, non_blocking=True)\n",
    "\n",
    "    batch_targets = [{k: v.to(device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "    # forward with amp (mixed precision)\n",
    "    with torch.autocast(device_type=device, cache_enabled=True):\n",
    "      outputs = model(batch_images, batch_targets)\n",
    "    with torch.autocast(device_type=device, cache_enabled=False):\n",
    "      loss_dict = criterion(outputs, batch_targets)\n",
    "\n",
    "    loss=sum(loss_dict.values())\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    # gradient clipping\n",
    "    if max_norm > 0:\n",
    "      scaler.unscale_(optimizer)\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    optimizer.zero_grad() # zero grad for the next run\n",
    "\n",
    "    if lr_warmup_scheduler is not None:\n",
    "        lr_warmup_scheduler.step()\n",
    "\n",
    "    # track loss\n",
    "    loss_total += loss.item()\n",
    "    num_batches += 1\n",
    "\n",
    "    # Update tqdm bar with the current loss\n",
    "    progress_bar.set_postfix({\"batch_loss\": loss.item()})\n",
    "\n",
    "  # Close tqdm bar\n",
    "  progress_bar.close()\n",
    "\n",
    "  # Return average loss\n",
    "  return loss_total / num_batches if num_batches > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1734009886748,
     "user": {
      "displayName": "Tai Do",
      "userId": "13979933527558473981"
     },
     "user_tz": -480
    },
    "id": "qcckg2AXdoZh"
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "# model output as a class -> to suit post processing method\n",
    "@dataclass\n",
    "class ModelOutput:\n",
    "    logits: torch.Tensor\n",
    "    pred_boxes: torch.Tensor\n",
    "\n",
    "\n",
    "# compute mAP50 and mAP50-100 in validation\n",
    "def validate(model, loader, processor, threshold, device):\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize tqdm progress bar and evaluator\n",
    "    progress_bar = tqdm(loader, desc=\"Validating\", leave=True)\n",
    "    evaluator = MeanAveragePrecision(box_format=\"xyxy\", class_metrics=True)\n",
    "    evaluator.warn_on_many_detections = False\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # Move batch data to the correct device\n",
    "        images = batch['pixel_values'].to(device)\n",
    "        batch_targets = batch['labels']\n",
    "\n",
    "        # (1) Prepare target sizes and targets\n",
    "        target_sizes = torch.tensor(np.array([x[\"orig_size\"] for x in batch_targets])).to(device)\n",
    "        batch_targets_processed = []\n",
    "\n",
    "        # loop through individual targets\n",
    "        for target, (height,width) in zip(batch_targets,target_sizes):\n",
    "            boxes=target['boxes'].cpu().numpy()\n",
    "            # convert to xyxy and compute actual dimensions\n",
    "            boxes=sv.xcycwh_to_xyxy(boxes)\n",
    "            boxes=boxes*np.array([width.item(),height.item(),width.item(),height.item()])\n",
    "            boxes=torch.tensor(boxes, device=device)\n",
    "            labels=target[\"labels\"].to(device)\n",
    "            batch_targets_processed.append({\n",
    "                \"boxes\": boxes,\n",
    "                \"labels\": labels\n",
    "            })\n",
    "\n",
    "        # (2) Compute predictions and post-process them\n",
    "        with torch.no_grad():\n",
    "            preds = model(images)\n",
    "            outputs = ModelOutput(\n",
    "                logits=preds['pred_logits'],\n",
    "                pred_boxes=preds['pred_boxes']\n",
    "            )\n",
    "            batch_preds_processed = processor.post_process_object_detection(\n",
    "                outputs,\n",
    "                threshold=threshold,\n",
    "                target_sizes=target_sizes\n",
    "            )\n",
    "\n",
    "        # (3) Update evaluator incrementally\n",
    "        preds_for_evaluator = [\n",
    "            {\n",
    "                \"boxes\": pred[\"boxes\"].cpu(),\n",
    "                \"scores\": pred[\"scores\"].cpu(),\n",
    "                \"labels\": pred[\"labels\"].cpu()\n",
    "            }\n",
    "            for pred in batch_preds_processed\n",
    "        ]\n",
    "        targets_for_evaluator = [\n",
    "            {\n",
    "                \"boxes\": target[\"boxes\"].cpu(),\n",
    "                \"labels\": target[\"labels\"].cpu()\n",
    "            }\n",
    "            for target in batch_targets_processed\n",
    "        ]\n",
    "        evaluator.update(preds=preds_for_evaluator, target=targets_for_evaluator)\n",
    "\n",
    "    # Compute final metrics\n",
    "    metrics = evaluator.compute()\n",
    "    mAP50 = metrics[\"map_50\"].item()\n",
    "    mAP50_95 = metrics[\"map\"].item()\n",
    "\n",
    "    #print(f\"mAP@50: {mAP50:.4f}, mAP@50-95: {mAP50_95:.4f}\")\n",
    "    return mAP50, mAP50_95\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1734009886748,
     "user": {
      "displayName": "Tai Do",
      "userId": "13979933527558473981"
     },
     "user_tz": -480
    },
    "id": "smmFlErKdtCX"
   },
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "def train(model, train_loader, val_loader, criterion, processor,device=\"cuda\",num_epochs=100, threshold=0.01):\n",
    "    # Define optimizer, criterion, and scheduler\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=0.000714, # ultralytics lr\n",
    "        betas=(0.9, 0.999),\n",
    "        weight_decay=0.0005\n",
    "    )\n",
    "\n",
    "\n",
    "    # Learning rate warmup scheduler\n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    lr_warmup_scheduler = get_scheduler(\n",
    "        name=\"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=500,\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "\n",
    "    best_model = None\n",
    "    best_map50 = 0\n",
    "    device = \"cuda\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Apply warmup scheduler only in the first epoch\n",
    "        current_lr_scheduler = lr_warmup_scheduler if epoch == 0 else None\n",
    "\n",
    "        # Single training call\n",
    "        train_loss = train_one_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            criterion,\n",
    "            max_norm=0.1,\n",
    "            device=device,\n",
    "            lr_warmup_scheduler=lr_warmup_scheduler\n",
    "        )\n",
    "\n",
    "        # Validation\n",
    "        map50, map50_95 = validate(\n",
    "            model,\n",
    "            val_loader,\n",
    "            processor=processor,\n",
    "            threshold=threshold,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        print(f\"--------- Epoch {epoch + 1}/{num_epochs} --------- \")\n",
    "        print(f\"train_loss: {train_loss:.4f} | val_map50: {map50:.4f} | val_map50_95: {map50_95:.4f}\")\n",
    "\n",
    "        # Update best model\n",
    "        if map50 > best_map50:\n",
    "            best_map50 = map50\n",
    "            best_model = model.state_dict()  # Save model state dict, not the entire model\n",
    "\n",
    "    return best_model, best_map50\n",
    "\n",
    "\n",
    "# processor for evaluator\n",
    "processor=AutoImageProcessor.from_pretrained(\n",
    "            \"PekingU/rtdetr_r18vd_coco_o365\",\n",
    "            do_resize=True,\n",
    "            size={\"width\": 640, \"height\": 640},)\n",
    "# Hungarian matching loss\n",
    "criterion = cfg.criterion\n",
    "train(model=model, train_loader=train_loader, val_loader=val_loader, criterion=criterion, processor=processor, device=\"cuda\", num_epochs=10, threshold=0.01)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOdV1B0CY/o+Yukb+q6mLvX",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0044f6ec17834d3688ded99cc673869b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "127ba9e807354849863306bec86743b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0044f6ec17834d3688ded99cc673869b",
      "max": 841,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b9baa987f36445c685167f3ec7670ec0",
      "value": 841
     }
    },
    "1f411e442985453faf0595f8dc721ee3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae454599c67346a58631a63b8a05a649",
      "placeholder": "​",
      "style": "IPY_MODEL_46f751388868434f9cb0c29182592c41",
      "value": " 841/841 [00:00&lt;00:00, 11.2kB/s]"
     }
    },
    "46f751388868434f9cb0c29182592c41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "690d53e82fb5480495fd2a1ba4e04be2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0dc6b04e07e407b99c7699756e3d7b3",
      "placeholder": "​",
      "style": "IPY_MODEL_d86ac78805d04778aa81a71cf8f595ee",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "ae454599c67346a58631a63b8a05a649": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9baa987f36445c685167f3ec7670ec0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d86ac78805d04778aa81a71cf8f595ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e324c427549a4798b7c968cb826968eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0dc6b04e07e407b99c7699756e3d7b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa03931dfc6a4ba69f65fe5a3398a29f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_690d53e82fb5480495fd2a1ba4e04be2",
       "IPY_MODEL_127ba9e807354849863306bec86743b8",
       "IPY_MODEL_1f411e442985453faf0595f8dc721ee3"
      ],
      "layout": "IPY_MODEL_e324c427549a4798b7c968cb826968eb"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
